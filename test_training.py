"""
æµ‹è¯•è®­ç»ƒæµç¨‹ - ç®€åŒ–ç‰ˆæœ¬
"""
import sys
import os
sys.path.append('.')

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
import numpy as np

# åˆ›å»ºç®€å•çš„æ•°æ®é›†ç±»
class DummyDataset(Dataset):
    def __init__(self, size=100):
        self.size = size

    def __len__(self):
        return self.size

    def __getitem__(self, idx):
        image = torch.randn(3, 224, 224)
        label = torch.randint(0, 21, (224, 224))
        return image, label

# ç®€åŒ–çš„åˆ†å‰²æ¨¡å‹
class SimpleSegModel(nn.Module):
    def __init__(self, num_classes=21):
        super(SimpleSegModel, self).__init__()

        # ç¼–ç å™¨
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, 3, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),

            nn.Conv2d(32, 64, 3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),

            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
        )

        # è§£ç å™¨
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),

            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),

            nn.ConvTranspose2d(32, num_classes, 4, stride=2, padding=1),
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

def test_training_pipeline():
    print("ğŸš€ å¼€å§‹æµ‹è¯•è®­ç»ƒæµç¨‹...")

    # 1. åˆ›å»ºæ¨¡å‹
    model = SimpleSegModel(num_classes=21)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataset = DummyDataset(size=20)
    dataloader = DataLoader(dataset, batch_size=2, shuffle=True)
    print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸï¼Œæ•°æ®é›†å¤§å°: {len(dataset)}")

    # 3. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
    print("âœ… æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")

    # 4. æµ‹è¯•ä¸€ä¸ªè®­ç»ƒæ­¥éª¤
    model.train()
    for batch_idx, (images, labels) in enumerate(dataloader):
        if batch_idx >= 2:  # åªæµ‹è¯•2ä¸ªbatch
            break

        # å‰å‘ä¼ æ’­
        outputs = model(images)
        loss = criterion(outputs, labels)

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        print(f"  Batch {batch_idx}: loss = {loss.item():.4f}")

    print("âœ… è®­ç»ƒæµç¨‹æµ‹è¯•æˆåŠŸï¼")

    # 5. æµ‹è¯•è¯„ä¼°
    model.eval()
    with torch.no_grad():
        test_images, test_labels = next(iter(dataloader))
        test_outputs = model(test_images)
        test_loss = criterion(test_outputs, test_labels)

        # è®¡ç®—å‡†ç¡®ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
        pred = torch.argmax(test_outputs, dim=1)
        accuracy = (pred == test_labels).float().mean()

        print(f"âœ… è¯„ä¼°æµ‹è¯•æˆåŠŸ: loss = {test_loss.item():.4f}, accuracy = {accuracy.item():.4f}")

    return model

if __name__ == "__main__":
    try:
        model = test_training_pipeline()
        print("\nğŸ‰ è®­ç»ƒç³»ç»Ÿæµ‹è¯•å®Œå…¨æˆåŠŸï¼")
        print("ç°åœ¨å¯ä»¥å¼€å§‹è¿ç§»æ›´å¤æ‚çš„æ¨¡å‹å’Œé…ç½®ç³»ç»Ÿã€‚")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
