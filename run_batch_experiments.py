#!/usr/bin/env python3
"""
å¤šæ•°æ®é›†æ‰¹é‡å®éªŒè„šæœ¬
æŒ‰é˜¶æ®µè¿è¡Œä¸åŒæ•°æ®é›†çš„å®éªŒï¼Œå®ç°æ¸è¿›å¼éªŒè¯
"""

import os
import sys
import time
import logging
from pathlib import Path
from typing import List, Dict, Any
import subprocess
import yaml

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from configs.config_manager import ConfigManager
from utils.logger import setup_logger

def setup_experiment_logger(experiment_name: str) -> logging.Logger:
    """è®¾ç½®å®éªŒä¸“ç”¨æ—¥å¿—"""
    log_dir = project_root / 'experiments' / experiment_name / 'logs'
    log_dir.mkdir(parents=True, exist_ok=True)

    logger = setup_logger(
        name=f'experiment_{experiment_name}',
        log_file=str(log_dir / 'experiment.log'),
        level=logging.INFO
    )
    return logger

def run_single_experiment(config_file: str, stage_name: str) -> Dict[str, Any]:
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    logger = logging.getLogger('batch_experiment')

    try:
        # åŠ è½½é…ç½®
        config = ConfigManager(config_file)
        experiment_name = config.experiment.name

        logger.info(f"å¼€å§‹{stage_name}: {experiment_name}")
        logger.info(f"é…ç½®æ–‡ä»¶: {config_file}")

        # è®¾ç½®å®éªŒä¸“ç”¨æ—¥å¿—
        exp_logger = setup_experiment_logger(experiment_name)

        # è®°å½•å®éªŒå¼€å§‹æ—¶é—´
        start_time = time.time()

        # è¿è¡Œè®­ç»ƒè„šæœ¬
        cmd = [
            sys.executable, 'train_complete.py',
            '--config', config_file,
            '--experiment_name', experiment_name
        ]

        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")

        # æ‰§è¡Œè®­ç»ƒ
        result = subprocess.run(
            cmd,
            cwd=str(project_root),
            capture_output=True,
            text=True,
            timeout=7200  # 2å°æ—¶è¶…æ—¶
        )

        # è®°å½•å®éªŒç»“æŸæ—¶é—´
        end_time = time.time()
        duration = end_time - start_time

        # å¤„ç†ç»“æœ
        if result.returncode == 0:
            logger.info(f"{stage_name}æˆåŠŸå®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
            exp_logger.info(f"å®éªŒæˆåŠŸå®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")

            # è§£æè¾“å‡ºä¸­çš„æŒ‡æ ‡
            metrics = parse_metrics_from_output(result.stdout)

            return {
                'success': True,
                'duration': duration,
                'metrics': metrics,
                'config_file': config_file,
                'experiment_name': experiment_name
            }
        else:
            error_msg = f"{stage_name}å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}"
            logger.error(error_msg)
            logger.error(f"æ ‡å‡†è¾“å‡º: {result.stdout}")
            logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")

            exp_logger.error(error_msg)
            exp_logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")

            return {
                'success': False,
                'duration': duration,
                'error': result.stderr,
                'config_file': config_file,
                'experiment_name': experiment_name
            }

    except subprocess.TimeoutExpired:
        error_msg = f"{stage_name}è¶…æ—¶ï¼ˆ2å°æ—¶ï¼‰"
        logger.error(error_msg)
        return {
            'success': False,
            'duration': 7200,
            'error': 'å®éªŒè¶…æ—¶',
            'config_file': config_file
        }
    except Exception as e:
        error_msg = f"{stage_name}å¼‚å¸¸: {str(e)}"
        logger.error(error_msg)
        return {
            'success': False,
            'duration': 0,
            'error': str(e),
            'config_file': config_file
        }

def parse_metrics_from_output(output: str) -> Dict[str, float]:
    """ä»è¾“å‡ºä¸­è§£ææŒ‡æ ‡"""
    metrics = {}

    lines = output.split('\n')
    for line in lines:
        if 'Final mIoU:' in line:
            try:
                miou = float(line.split('Final mIoU:')[1].strip().replace('%', ''))
                metrics['miou'] = miou
            except:
                pass
        elif 'Pixel Accuracy:' in line:
            try:
                acc = float(line.split('Pixel Accuracy:')[1].strip().replace('%', ''))
                metrics['pixel_accuracy'] = acc
            except:
                pass

    return metrics

def generate_summary_report(results: List[Dict[str, Any]]) -> None:
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    logger = logging.getLogger('batch_experiment')

    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    report_dir = project_root / 'experiments' / 'batch_experiment_report'
    report_dir.mkdir(parents=True, exist_ok=True)

    # ç”ŸæˆæŠ¥å‘Š
    report_file = report_dir / f'summary_{int(time.time())}.md'

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# å¤šæ•°æ®é›†æ‰¹é‡å®éªŒæŠ¥å‘Š\n\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        # ç»Ÿè®¡ä¿¡æ¯
        total_experiments = len(results)
        successful_experiments = sum(1 for r in results if r['success'])
        failed_experiments = total_experiments - successful_experiments
        total_duration = sum(r['duration'] for r in results)

        f.write("## å®éªŒç»Ÿè®¡\n\n")
        f.write(f"- æ€»å®éªŒæ•°: {total_experiments}\n")
        f.write(f"- æˆåŠŸå®éªŒ: {successful_experiments}\n")
        f.write(f"- å¤±è´¥å®éªŒ: {failed_experiments}\n")
        f.write(f"- æ€»è€—æ—¶: {total_duration:.2f}ç§’ ({total_duration/3600:.2f}å°æ—¶)\n\n")

        # æˆåŠŸå®éªŒè¯¦æƒ…
        f.write("## æˆåŠŸå®éªŒç»“æœ\n\n")
        f.write("| å®éªŒåç§° | æ•°æ®é›† | é…ç½®æ–‡ä»¶ | è€—æ—¶(åˆ†é’Ÿ) | mIoU(%) | Pixel Acc(%) |\n")
        f.write("|----------|--------|----------|------------|---------|-------------|\n")

        for result in results:
            if result['success']:
                duration_min = result['duration'] / 60
                miou = result['metrics'].get('miou', 'N/A')
                pixel_acc = result['metrics'].get('pixel_accuracy', 'N/A')
                dataset_type = extract_dataset_type(result['config_file'])

                f.write(f"| {result['experiment_name']} | {dataset_type} | {result['config_file']} | {duration_min:.1f} | {miou} | {pixel_acc} |\n")

        # å¤±è´¥å®éªŒè¯¦æƒ…
        if failed_experiments > 0:
            f.write("\n## å¤±è´¥å®éªŒè¯¦æƒ…\n\n")
            for result in results:
                if not result['success']:
                    f.write(f"### {result.get('experiment_name', 'Unknown')}\n")
                    f.write(f"- é…ç½®æ–‡ä»¶: {result['config_file']}\n")
                    f.write(f"- é”™è¯¯ä¿¡æ¯: {result['error']}\n\n")

        # æ€§èƒ½å¯¹æ¯”
        f.write("\n## æ€§èƒ½å¯¹æ¯”åˆ†æ\n\n")
        f.write("### ä¸åŒæ•°æ®é›†æ€§èƒ½å¯¹æ¯”\n\n")

        dataset_performance = {}
        for result in results:
            if result['success'] and 'miou' in result['metrics']:
                dataset = extract_dataset_type(result['config_file'])
                if dataset not in dataset_performance:
                    dataset_performance[dataset] = []
                dataset_performance[dataset].append(result['metrics']['miou'])

        for dataset, mious in dataset_performance.items():
            avg_miou = sum(mious) / len(mious)
            f.write(f"- **{dataset}**: å¹³å‡mIoU = {avg_miou:.2f}%\n")

        # å»ºè®®å’Œæ€»ç»“
        f.write("\n## å»ºè®®å’Œæ€»ç»“\n\n")

        if successful_experiments == total_experiments:
            f.write("âœ… æ‰€æœ‰å®éªŒæˆåŠŸå®Œæˆï¼\n\n")
            f.write("**å»ºè®®ä¸‹ä¸€æ­¥:**\n")
            f.write("1. åˆ†æå„æ•°æ®é›†çš„æ€§èƒ½å·®å¼‚\n")
            f.write("2. å°è¯•æ›´å¤æ‚çš„æ¨¡å‹æ¶æ„\n")
            f.write("3. è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–\n")
            f.write("4. å®æ–½æ¨¡å‹é›†æˆç­–ç•¥\n")
        elif successful_experiments > 0:
            f.write(f"âš ï¸ éƒ¨åˆ†å®éªŒå¤±è´¥ ({failed_experiments}/{total_experiments})\n\n")
            f.write("**å»ºè®®:**\n")
            f.write("1. æ£€æŸ¥å¤±è´¥å®éªŒçš„é”™è¯¯ä¿¡æ¯\n")
            f.write("2. è°ƒæ•´é…ç½®å‚æ•°\n")
            f.write("3. æ£€æŸ¥æ•°æ®é›†è·¯å¾„å’Œæ ¼å¼\n")
            f.write("4. ç¡®ä¿è®¡ç®—èµ„æºå……è¶³\n")
        else:
            f.write("âŒ æ‰€æœ‰å®éªŒå¤±è´¥ï¼\n\n")
            f.write("**ç´§æ€¥å»ºè®®:**\n")
            f.write("1. æ£€æŸ¥ç¯å¢ƒé…ç½®\n")
            f.write("2. éªŒè¯æ•°æ®é›†å®Œæ•´æ€§\n")
            f.write("3. ç®€åŒ–é…ç½®é‡æ–°æµ‹è¯•\n")
            f.write("4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—\n")

    logger.info(f"æ€»ç»“æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

def extract_dataset_type(config_file: str) -> str:
    """ä»é…ç½®æ–‡ä»¶åä¸­æå–æ•°æ®é›†ç±»å‹"""
    if 'voc2012' in config_file.lower():
        return 'VOC2012'
    elif 'ade20k' in config_file.lower():
        return 'ADE20K'
    elif 'cityscapes' in config_file.lower():
        return 'Cityscapes'
    else:
        return 'Unknown'

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logger = setup_logger(
        name='batch_experiment',
        log_file=str(project_root / 'experiments' / 'batch_experiment.log'),
        level=logging.INFO
    )

    logger.info("å¼€å§‹å¤šæ•°æ®é›†æ‰¹é‡å®éªŒ")

    # å®šä¹‰å®éªŒé˜¶æ®µ
    experiment_stages = [
        {
            'name': 'é˜¶æ®µ1: VOC2012å¿«é€ŸéªŒè¯',
            'config': 'configs/voc2012_quick_test.yaml',
            'description': 'éªŒè¯æ¨¡å‹æ¶æ„å’Œè®­ç»ƒæµç¨‹'
        },
        {
            'name': 'é˜¶æ®µ2: ADE20Kå…¨é¢è¯„ä¼°',
            'config': 'configs/ade20k_full_eval.yaml',
            'description': 'éªŒè¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›å’Œå¤šç±»åˆ«æ€§èƒ½'
        },
        {
            'name': 'é˜¶æ®µ3: Cityscapesé«˜ç²¾åº¦æµ‹è¯•',
            'config': 'configs/cityscapes_precision_test.yaml',
            'description': 'è¿½æ±‚æœ€é«˜ç²¾åº¦å’Œç»†èŠ‚ä¼˜åŒ–'
        }
    ]

    results = []
    total_start_time = time.time()

    for i, stage in enumerate(experiment_stages, 1):
        logger.info(f"\n{'='*60}")
        logger.info(f"å¼€å§‹ {stage['name']} ({i}/{len(experiment_stages)})")
        logger.info(f"æè¿°: {stage['description']}")
        logger.info(f"é…ç½®: {stage['config']}")
        logger.info(f"{'='*60}")

        # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        config_path = project_root / stage['config']
        if not config_path.exists():
            error_msg = f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}"
            logger.error(error_msg)
            results.append({
                'success': False,
                'duration': 0,
                'error': error_msg,
                'config_file': stage['config']
            })
            continue

        # è¿è¡Œå®éªŒ
        result = run_single_experiment(stage['config'], stage['name'])
        results.append(result)

        # å¦‚æœå®éªŒå¤±è´¥ä¸”æ˜¯å…³é”®é˜¶æ®µï¼Œè¯¢é—®æ˜¯å¦ç»§ç»­
        if not result['success'] and i == 1:  # VOC2012æ˜¯åŸºç¡€éªŒè¯
            logger.warning("åŸºç¡€éªŒè¯å®éªŒå¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥é…ç½®åé‡è¯•")
            logger.warning("ç»§ç»­åç»­å®éªŒå¯èƒ½ä¼šå¤±è´¥...")

    # è®°å½•æ€»ä½“å®Œæˆæ—¶é—´
    total_duration = time.time() - total_start_time
    logger.info(f"\næ‰€æœ‰å®éªŒå®Œæˆï¼Œæ€»è€—æ—¶: {total_duration:.2f}ç§’ ({total_duration/3600:.2f}å°æ—¶)")

    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_summary_report(results)

    # è¾“å‡ºç®€è¦ç»“æœ
    successful_count = sum(1 for r in results if r['success'])
    logger.info(f"å®éªŒç»“æœ: {successful_count}/{len(results)} æˆåŠŸ")

    if successful_count == len(results):
        logger.info("ğŸ‰ æ‰€æœ‰å®éªŒæˆåŠŸå®Œæˆï¼")
        return 0
    elif successful_count > 0:
        logger.warning(f"âš ï¸ éƒ¨åˆ†å®éªŒå¤±è´¥ ({len(results) - successful_count} ä¸ª)")
        return 1
    else:
        logger.error("âŒ æ‰€æœ‰å®éªŒå¤±è´¥ï¼")
        return 2

if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)
