#!/usr/bin/env python3
"""
å¤šæ•°æ®é›†æ¡†æ¶æµ‹è¯•è„šæœ¬
éªŒè¯universal_dataset.pyçš„åŠŸèƒ½
"""

import sys
from pathlib import Path
import torch
from torch.utils.data import DataLoader

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from datasets.universal_dataset import create_dataset

def test_dataset_creation():
    """æµ‹è¯•æ•°æ®é›†åˆ›å»º"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®é›†åˆ›å»ºåŠŸèƒ½...")

    # æµ‹è¯•å‚æ•°
    test_configs = [
        {
            'name': 'VOC2012',
            'type': 'voc2012',
            'root_dir': './datasets/VOC2012',
            'expected_classes': 21
        },
        {
            'name': 'ADE20K',
            'type': 'ade20k',
            'root_dir': './datasets/ADE20K',
            'expected_classes': 150
        },
        {
            'name': 'Cityscapes',
            'type': 'cityscapes',
            'root_dir': './datasets/Cityscapes',
            'expected_classes': 19
        }
    ]

    results = []

    for config in test_configs:
        print(f"\nğŸ“ æµ‹è¯• {config['name']} æ•°æ®é›†...")

        try:
            # åˆ›å»ºæ•°æ®é›†
            dataset = create_dataset(
                dataset_type=config['type'],
                root_dir=config['root_dir'],
                split='train',
                image_size=(256, 256)
            )

            print(f"âœ… {config['name']} æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
            print(f"   - æ•°æ®é›†å¤§å°: {len(dataset)}")
            print(f"   - é¢„æœŸç±»åˆ«æ•°: {config['expected_classes']}")
            print(f"   - å®é™…ç±»åˆ«æ•°: {dataset.num_classes}")

            # æ£€æŸ¥ç±»åˆ«æ•°æ˜¯å¦æ­£ç¡®
            if dataset.num_classes == config['expected_classes']:
                print(f"   - âœ… ç±»åˆ«æ•°æ­£ç¡®")
            else:
                print(f"   - âš ï¸ ç±»åˆ«æ•°ä¸åŒ¹é…")

            # æµ‹è¯•æ•°æ®åŠ è½½
            if len(dataset) > 0:
                try:
                    image, mask = dataset[0]
                    print(f"   - å›¾åƒå½¢çŠ¶: {image.shape}")
                    print(f"   - æ ‡ç­¾å½¢çŠ¶: {mask.shape}")
                    print(f"   - å›¾åƒæ•°æ®ç±»å‹: {image.dtype}")
                    print(f"   - æ ‡ç­¾æ•°æ®ç±»å‹: {mask.dtype}")
                    print(f"   - âœ… æ•°æ®åŠ è½½æ­£å¸¸")
                except Exception as e:
                    print(f"   - âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            else:
                print(f"   - âš ï¸ æ•°æ®é›†ä¸ºç©ºï¼ˆä½¿ç”¨dummyæ•°æ®ï¼‰")

            results.append({
                'name': config['name'],
                'success': True,
                'dataset': dataset
            })

        except Exception as e:
            print(f"âŒ {config['name']} æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
            results.append({
                'name': config['name'],
                'success': False,
                'error': str(e)
            })

    return results

def test_dataloader():
    """æµ‹è¯•DataLoader"""
    print("\nğŸ§ª æµ‹è¯•DataLoaderåŠŸèƒ½...")

    try:
        # åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ•°æ®é›†
        dataset = create_dataset(
            dataset_type='voc2012',
            root_dir='./datasets/VOC2012',
            split='train',
            image_size=(256, 256)
        )

        # åˆ›å»ºDataLoader
        dataloader = DataLoader(
            dataset,
            batch_size=2,
            shuffle=True,
            num_workers=0  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        )

        print(f"âœ… DataLoaderåˆ›å»ºæˆåŠŸ")
        print(f"   - æ‰¹æ¬¡å¤§å°: {dataloader.batch_size}")
        print(f"   - æ•°æ®é›†å¤§å°: {len(dataloader.dataset)}")

        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        for batch_idx, (images, masks) in enumerate(dataloader):
            print(f"   - æ‰¹æ¬¡ {batch_idx}:")
            print(f"     * å›¾åƒæ‰¹æ¬¡å½¢çŠ¶: {images.shape}")
            print(f"     * æ ‡ç­¾æ‰¹æ¬¡å½¢çŠ¶: {masks.shape}")
            print(f"     * å›¾åƒæ•°æ®èŒƒå›´: [{images.min():.3f}, {images.max():.3f}]")
            print(f"     * æ ‡ç­¾æ•°æ®èŒƒå›´: [{masks.min()}, {masks.max()}]")

            if batch_idx >= 1:  # åªæµ‹è¯•2ä¸ªæ‰¹æ¬¡
                break

        print(f"   - âœ… DataLoaderå·¥ä½œæ­£å¸¸")
        return True

    except Exception as e:
        print(f"âŒ DataLoaderæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_config_integration():
    """æµ‹è¯•é…ç½®æ–‡ä»¶é›†æˆ"""
    print("\nğŸ§ª æµ‹è¯•é…ç½®æ–‡ä»¶é›†æˆ...")

    try:
        from configs.config_manager import ConfigManager

        # æµ‹è¯•é…ç½®æ–‡ä»¶
        config_files = [
            'configs/voc2012_quick_test.yaml',
            'configs/ade20k_full_eval.yaml',
            'configs/cityscapes_precision_test.yaml'
        ]

        for config_file in config_files:
            config_path = project_root / config_file

            if config_path.exists():
                print(f"ğŸ“„ æµ‹è¯•é…ç½®æ–‡ä»¶: {config_file}")

                try:
                    # ç›´æ¥è¯»å–YAMLæ–‡ä»¶
                    import yaml
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config_data = yaml.safe_load(f)

                    # éªŒè¯å¿…è¦å­—æ®µ
                    required_fields = ['dataset', 'model', 'training', 'experiment']
                    missing_fields = []

                    for field in required_fields:
                        if field not in config_data:
                            missing_fields.append(field)

                    if not missing_fields:
                        print(f"   - âœ… é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¡®")
                        print(f"   - æ•°æ®é›†ç±»å‹: {config_data.get('dataset', {}).get('type', 'unknown')}")
                        print(f"   - å®éªŒåç§°: {config_data.get('experiment', {}).get('name', 'unknown')}")
                    else:
                        print(f"   - âš ï¸ ç¼ºå°‘å­—æ®µ: {missing_fields}")

                except Exception as e:
                    print(f"   - âŒ é…ç½®æ–‡ä»¶è§£æå¤±è´¥: {e}")
            else:
                print(f"ğŸ“„ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")

        print(f"âœ… é…ç½®æ–‡ä»¶é›†æˆæµ‹è¯•å®Œæˆ")
        return True

    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def generate_test_report(dataset_results, dataloader_success, config_success):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š å¤šæ•°æ®é›†æ¡†æ¶æµ‹è¯•æŠ¥å‘Š")
    print("="*60)

    # æ•°æ®é›†æµ‹è¯•ç»“æœ
    print("\nğŸ—‚ï¸ æ•°æ®é›†æµ‹è¯•ç»“æœ:")
    successful_datasets = 0
    for result in dataset_results:
        status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±è´¥"
        print(f"   - {result['name']}: {status}")
        if result['success']:
            successful_datasets += 1

    print(f"\næ•°æ®é›†æˆåŠŸç‡: {successful_datasets}/{len(dataset_results)} ({successful_datasets/len(dataset_results)*100:.1f}%)")

    # DataLoaderæµ‹è¯•ç»“æœ
    dataloader_status = "âœ… æˆåŠŸ" if dataloader_success else "âŒ å¤±è´¥"
    print(f"\nğŸ”„ DataLoaderæµ‹è¯•: {dataloader_status}")

    # é…ç½®æ–‡ä»¶æµ‹è¯•ç»“æœ
    config_status = "âœ… æˆåŠŸ" if config_success else "âŒ å¤±è´¥"
    print(f"âš™ï¸ é…ç½®æ–‡ä»¶æµ‹è¯•: {config_status}")

    # æ€»ä½“è¯„ä¼°
    total_tests = len(dataset_results) + 2
    successful_tests = successful_datasets + (1 if dataloader_success else 0) + (1 if config_success else 0)

    print(f"\nğŸ“ˆ æ€»ä½“æµ‹è¯•ç»“æœ: {successful_tests}/{total_tests} ({successful_tests/total_tests*100:.1f}%)")

    if successful_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤šæ•°æ®é›†æ¡†æ¶å·¥ä½œæ­£å¸¸ã€‚")
        recommendation = """
ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:
1. å‡†å¤‡çœŸå®æ•°æ®é›†å¹¶æ”¾ç½®åˆ°æ­£ç¡®ç›®å½•
2. è¿è¡Œå•æ•°æ®é›†å®éªŒéªŒè¯åŠŸèƒ½
3. æ‰§è¡Œæ‰¹é‡å®éªŒæµ‹è¯•å®Œæ•´æµç¨‹
4. æ ¹æ®å®éªŒç»“æœè°ƒä¼˜æ¨¡å‹å’Œå‚æ•°
        """
    elif successful_tests >= total_tests * 0.7:
        print("\nâš ï¸ å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œä½†æœ‰éƒ¨åˆ†é—®é¢˜éœ€è¦è§£å†³ã€‚")
        recommendation = """
ğŸ”§ å»ºè®®ä¿®å¤:
1. æ£€æŸ¥å¤±è´¥çš„æ•°æ®é›†é…ç½®
2. ç¡®è®¤æ•°æ®é›†è·¯å¾„å’Œæ ¼å¼
3. éªŒè¯é…ç½®æ–‡ä»¶å®Œæ•´æ€§
4. ä¿®å¤åé‡æ–°æµ‹è¯•
        """
    else:
        print("\nâŒ å¤šä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥æ¡†æ¶é…ç½®ã€‚")
        recommendation = """
ğŸš¨ ç´§æ€¥ä¿®å¤:
1. æ£€æŸ¥é¡¹ç›®ä¾èµ–å’Œç¯å¢ƒ
2. éªŒè¯ä»£ç å®Œæ•´æ€§
3. ç¡®è®¤é…ç½®æ–‡ä»¶æ ¼å¼
4. é‡æ–°å®‰è£…æˆ–é‡æ„ä»£ç 
        """

    print(recommendation)

    return successful_tests == total_tests

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¤šæ•°æ®é›†æ¡†æ¶åŠŸèƒ½æµ‹è¯•")
    print("="*60)

    # è¿è¡Œæµ‹è¯•
    dataset_results = test_dataset_creation()
    dataloader_success = test_dataloader()
    config_success = test_config_integration()

    # ç”ŸæˆæŠ¥å‘Š
    all_passed = generate_test_report(dataset_results, dataloader_success, config_success)

    return 0 if all_passed else 1

if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)
